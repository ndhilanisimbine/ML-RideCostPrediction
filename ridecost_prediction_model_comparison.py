# -*- coding: utf-8 -*-
"""RideCost_Prediction_Model_Comparison.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vZWRiOI1H0B_FcOXKLrIevfP6x6W8BFF
"""

import pandas as pd
from google.colab import files

# Upload file
uploaded = files.upload()

# Load the dataset into df
df = pd.read_csv("ncr_ride_bookings.csv")
print("Shape before cleaning:", df.shape)

# Keep only completed rides
df = df[df["Booking Status"] == "Completed"]
print("Shape after filtering Completed rides:", df.shape)

# Show a quick preview
print(df.head(3))

# Drop rows missing Ride Distance or Avg CTAT (duration)
df = df.dropna(subset=["Ride Distance", "Avg CTAT"])
print("After dropping missing values:", df.shape)

df = df.rename(columns={
    "Booking ID": "booking_id",
    "Pickup Location": "pickup_location",
    "Drop Location": "drop_location",
    "Ride Distance": "distance_km",
    "Avg CTAT": "duration_min"
})

df["datetime"] = pd.to_datetime(df["Date"] + " " + df["Time"], errors="coerce")
df["hour"] = df["datetime"].dt.hour
df["day_of_week"] = df["datetime"].dt.dayofweek

df = df[(df["duration_min"] > 1) & (df["duration_min"] < 180)]
df = df[(df["distance_km"] > 0.1) & (df["distance_km"] < 100)]

df["speed_kmh"] = df["distance_km"] / (df["duration_min"] / 60)
df = df[(df["speed_kmh"] > 3) & (df["speed_kmh"] < 120)]

df = df[(df["duration_min"] > 1) & (df["duration_min"] < 180)]
df = df[(df["distance_km"] > 0.1) & (df["distance_km"] < 100)]

df["speed_kmh"] = df["distance_km"] / (df["duration_min"] / 60)
df = df[(df["speed_kmh"] > 3) & (df["speed_kmh"] < 120)]

clean = df[["booking_id", "pickup_location", "drop_location",
            "distance_km", "duration_min", "hour", "day_of_week"]]

clean.to_csv("ncr_clean.csv", index=False)
print("✅ Clean dataset saved as ncr_clean.csv with shape:", clean.shape)

import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
plt.scatter(df["distance_km"], df["duration_min"], alpha=0.3)
plt.xlabel("Distance (km)")
plt.ylabel("Duration (minutes)")
plt.title("Distance vs Duration (Cleaned Data)")
plt.show()

df["is_weekend"] = df["day_of_week"].apply(lambda x: 1 if x >= 5 else 0)
df["is_rush_hour"] = df["hour"].apply(lambda h: 1 if (7 <= h <= 10) or (17 <= h <= 20) else 0)

# --- Distance transformation ---
import numpy as np
df["log_distance"] = np.log1p(df["distance_km"])

# --- Location encoding (Label Encoding for now) ---
from sklearn.preprocessing import LabelEncoder

le_pickup = LabelEncoder()
le_drop = LabelEncoder()

df["pickup_encoded"] = le_pickup.fit_transform(df["pickup_location"])
df["drop_encoded"] = le_drop.fit_transform(df["drop_location"])

# --- Final feature set preview ---
features = ["distance_km", "log_distance", "hour", "day_of_week",
            "is_weekend", "is_rush_hour", "pickup_encoded", "drop_encoded"]
target = "duration_min"

print("Features:", features)
print("Target:", target)
df[features + [target]].head()

import pandas as pd

# Load your cleaned dataset
df = pd.read_csv("ncr_clean.csv")
print("Dataset shape:", df.shape)
df.head()

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv("ncr_ride_bookings.csv")
print("✅ Re‑loaded dataset shape:", df.shape)
df.head()

df = df.dropna(subset=["Ride Distance", "Avg CTAT"])

print(df.columns)

features = ["Ride Distance"]
target = "Avg CTAT"

X = df[features]
y = df[target]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Initialize and train model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(X_test)

# Evaluate model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R^2 Score:", r2)

# Use more features
features = ['Ride Distance', 'Booking Value', 'Driver Ratings', 'Customer Rating', 'Vehicle Type']
target = 'Avg CTAT'

# One-hot encode 'Vehicle Type' since it's categorical
df_encoded = pd.get_dummies(df[features + [target]], drop_first=True)

# Split features and target again
X = df_encoded.drop(columns=[target])
y = df_encoded[target]

# Split train/test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.impute import SimpleImputer

# Replace NaN with the mean of each column
imputer = SimpleImputer(strategy='mean')
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R^2 Score:", r2)

model = RandomForestRegressor(n_estimators=10, random_state=42)

model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Initialize model
model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)

# Train model
model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(X_test)

# Evaluate model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R^2 Score:", r2)

import matplotlib.pyplot as plt
import numpy as np

# Get feature importances
importances = model.feature_importances_
feature_names = X.columns  # This assumes X was a DataFrame, not a NumPy array

# Sort feature importances
indices = np.argsort(importances)

# Plot
plt.figure(figsize=(10, 6))
plt.title("Feature Importances from Random Forest")
plt.barh(range(len(importances)), importances[indices], align="center")
plt.yticks(range(len(importances)), feature_names[indices])
plt.xlabel("Importance Score")
plt.tight_layout()
plt.show()

feature_names = ['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6']

print("Linear Regression Results:")
print(f"  - MSE: {78.74}")
print(f"  - R² Score: {0.009}")

print("Random Forest Results (n_estimators=50, max_depth=10):")
print(f"  - MSE: {72.16}")
print(f"  - R² Score: {0.092}")

plt.figure(figsize=(10, 6))
plt.title("Feature Importances from Random Forest")
plt.barh(range(len(importances)), importances[indices], align="center")
plt.yticks(range(len(importances)), feature_names[indices])
plt.xlabel("Importance Score")
plt.tight_layout()
plt.savefig("feature_importances.png", dpi=300)  # Save as high-res PNG
plt.show()